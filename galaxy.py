# -*- coding: utf-8 -*-
"""galaxy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fEvicnUxsuY2gYEj2rAO_zAFWn50vPo4

# Galaxy classification using convolutional networks

The student should:
  1. Preprocess the images.
  
  2. Design the network architecture and train it.
  
  3. Validate the network.

Las fotografías tienen un tamaño 424x424
"""

import torch
import math
import tensorflow as tf
import pandas as pd
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

"""## Pre-procesado de imágenes.

El primero paso será clonar el repositorio de las imágenes de entrenamiento. Este comando solo será necesario ejecutarlo una vez. Suele tardar unos 40 segundos aunque depende de la velocidad de bajada de *internet*. Las imágenes están guardadas en formato `.jpg`
"""

! git clone https://github.com/Wolfxyz16/galaxy-classification
# Este paso es necesario, sino llenamos toda la RAM del collab
! rm -rf galaxy-classification/images_training_rev1/

"""Una vez ya hemos clonado la carpeta, vamos a leer el archivo .csv y cargarlo en en un diccionario de Python."""

df = pd.read_csv("galaxy-classification/random_galaxies.csv")

galaxies = df.to_dict(orient = "records")

# Imprimimos las claves de los diccionarios almacenados
print(galaxies[0].keys())
print(f"Número total de galaxias: {len(galaxies)}")

"""Ahora utilizaremos `torchvision` para cargar las imágenes de las galaxias, pre procesarlas y después guardarlas."""

# Calculamos cuantas fotos tenemos
size = len(galaxies)
galaxies_images = []
image_size = 200

# Recorremos todo el diccionario de galaxias
for galaxy in galaxies:
  # Leemos la imagen como bytes
  imagen_bytes = tf.io.read_file(f"galaxy-classification/galaxies/" + str(galaxy["GalaxyID"]) + ".jpg")

  # Decodificamos la imagen
  imagen = tf.io.decode_jpeg(imagen_bytes, channels = 3)

  # Cambiamos el tamaño a 400x400
  imagen = tf.image.resize(imagen, [image_size, image_size])

  # Normalizar los valores entre [0, 1]
  imagen = imagen / 255.0

  galaxies_images.append(imagen)

print(f"{size + 1} images loaded in list galaxies_images")

"""Una vez con todas las imágenes cargadas y normalizadas vamos a crear las particinoes de entrenamiento y validación. Para ello vamos a crear dos objetos de tipo `DataLoader` que nos ayudarán a la hora de entrenar y evaluar."""

train_size = int(0.8 * len(galaxies_images))
test_size = len(galaxies_images) - train_size

# Dividimos los dos datasets
train_images, test_images = torch.utils.data.random_split(galaxies_images, [train_size, test_size])

# Creamos los objetos de tipo

"""Definimos nuestro modelo de red convolucional."""

import torch.nn as nn

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        # Capa convolucional 1
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 3 canales de entrada (RGB), 32 filtros, tamaño 3x3
        self.pool = nn.MaxPool2d(2, 2)  # Max pooling de 2x2

        # Capa convolucional 2
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)

        # Capa convolucional 3
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        # Capa densa (fully connected)
        self.fc1 = nn.Linear(128 * 4 * 4, 512)  # 128 filtros, imagen de tamaño 8x8 tras el pooling
        self.fc2 = nn.Linear(512, 10)  # 10 clases (salida de 10 neuronas)

    def forward(self, x):
        # Pasar por la red convolucional
        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 + ReLU + Pooling
        x = self.pool(torch.relu(self.conv2(x)))  # Conv2 + ReLU + Pooling
        x = torch.relu(self.conv3(x))             # Conv3 + ReLU (sin pooling aquí)

        # Aplanar la salida antes de pasarlo a la capa densa
        x = x.view(-1, 128 * 4 * 4)  # Cambiar la forma del tensor (flatten)

        # Pasar por la capa densa
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)

        return x

model = CNN()

print(model)

"""Una vez hemos definido nuestro modelo vamos a entrenarlo con los datos que hemos cargado."""

# Esto un poco copiao del lab de CNN
def train_loop(dataloader, model, loss_fn, optimizer, device):
  model.train()
  size = len(galaxies_images)
  train_loss, train_acc = 0, 0

  for epoch in range(5):
    X = X.to(device)
    y = y.to(device)
    # Compute prediction and loss
    pred = model(X)
    loss = loss_fn(pred, y)

    # Backpropagation
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # Store loss and accuracy
    train_loss += loss.item()
    train_acc += (pred.argmax(1) == y).type(torch.float).sum().item()

    if batch % 100 == 0:
      loss, current = loss.item(), batch * len(X)
      print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

  train_loss /= num_batches
  train_acc /= size
  return train_loss, train_acc

def test_loop(dataloader, model, loss_fn, device):
    model.eval()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss, test_acc = 0, 0

    with torch.no_grad():
        for X, y in dataloader:
          X = X.to(device)
          y = y.to(device)
          pred = model(X)
          test_loss += loss_fn(pred, y).item()
          test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()

    test_loss /= num_batches
    test_acc /= size
    print(f"Test Error: \n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f} \n")
    return test_loss, test_acc
